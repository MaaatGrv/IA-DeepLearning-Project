{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table des Matières\n",
    "\n",
    "1. [Introduction](https://chatgpt.com/c/6755b38f-32a8-8010-b45f-f9ddc4e36e80#Introduction)\n",
    "2. [Étape 1 : Importer les Bibliothèques Nécessaires](https://chatgpt.com/c/6755b38f-32a8-8010-b45f-f9ddc4e36e80#%C3%89tape-1-Importer-les-Biblioth%C3%A8ques-N%C3%A9cessaires)\n",
    "3. [Étape 2 : Définir les Fonctions de Prétraitement et d’Augmentation](https://chatgpt.com/c/6755b38f-32a8-8010-b45f-f9ddc4e36e80#%C3%89tape-2-D%C3%A9finir-les-Fonctions-de-Pr%C3%A9traitement-et-d%E2%80%99Augmentation)\n",
    "4. [Étape 3 : Définir la Fonction de Création des Modèles](https://chatgpt.com/c/6755b38f-32a8-8010-b45f-f9ddc4e36e80#%C3%89tape-3-D%C3%A9finir-la-Fonction-de-Cr%C3%A9ation-des-Mod%C3%A8les)\n",
    "5. [Étape 4 : Définir la Fonction de Téléchargement Audio depuis YouTube](https://chatgpt.com/c/6755b38f-32a8-8010-b45f-f9ddc4e36e80#%C3%89tape-4-D%C3%A9finir-la-Fonction-de-T%C3%A9l%C3%A9chargement-Audio-depuis-YouTube)\n",
    "6. [Étape 5 : Initialiser les Hyperparamètres](https://chatgpt.com/c/6755b38f-32a8-8010-b45f-f9ddc4e36e80#%C3%89tape-5-Initialiser-les-Hyperparam%C3%A8tres)\n",
    "7. [Étape 6 : Charger et Prétraiter les Données](https://chatgpt.com/c/6755b38f-32a8-8010-b45f-f9ddc4e36e80#%C3%89tape-6-Charger-et-Pr%C3%A9traiter-les-Donn%C3%A9es)\n",
    "8. [Étape 7 : Itérer sur les Combinaisons d'Hyperparamètres et Entraîner les Modèles](https://chatgpt.com/c/6755b38f-32a8-8010-b45f-f9ddc4e36e80#%C3%89tape-7-It%C3%A9rer-sur-les-Combinaisons-d'Hyperparam%C3%A8tres-et-Entra%C3%AEner-les-Mod%C3%A8les)\n",
    "9. [Étape 8 : Analyser et Sauvegarder les Résultats](https://chatgpt.com/c/6755b38f-32a8-8010-b45f-f9ddc4e36e80#%C3%89tape-8-Analyser-et-Sauvegarder-les-R%C3%A9sultats)\n",
    "10. [Étape 9 : Visualiser les Meilleurs Résultats](https://chatgpt.com/c/6755b38f-32a8-8010-b45f-f9ddc4e36e80#%C3%89tape-9-Visualiser-les-Meilleurs-R%C3%A9sultats)\n",
    "11. [Étape 10 : Sauvegarder et Charger les Meilleurs Modèles](https://chatgpt.com/c/6755b38f-32a8-8010-b45f-f9ddc4e36e80#%C3%89tape-10-Sauvegarder-et-Charger-les-Meilleurs-Mod%C3%A8les)\n",
    "12. [Étape 11 : Prédiction sur de Nouveaux Échantillons](https://chatgpt.com/c/6755b38f-32a8-8010-b45f-f9ddc4e36e80#%C3%89tape-11-Pr%C3%A9diction-sur-de-Nouveaux-%C3%89chantillons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Dans ce notebook, nous allons :\n",
    "\n",
    "1. **Charger et prétraiter les données audio** en extrayant les caractéristiques MFCC avec augmentation de données.\n",
    "2. **Définir et entraîner différents modèles** (CNN 2D, CNN profond, RNN avec LSTM/GRU) en testant diverses combinaisons d'hyperparamètres tels que la taille du batch, le nombre d'époques, le taux d'apprentissage et le nombre de coefficients MFCC.\n",
    "3. **Évaluer les performances** de chaque modèle et collecter les métriques dans un tableau pour une analyse comparative.\n",
    "4. **Visualiser les meilleurs résultats** et **sauvegarder les modèles** optimaux pour une utilisation future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 1 : Importer les Bibliothèques Nécessaires\n",
    "\n",
    "Tout d’abord, importons toutes les bibliothèques nécessaires pour le prétraitement des données, la création des modèles, et l’évaluation des performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import joblib\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, LSTM, GRU, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import yt_dlp as youtube_dl\n",
    "\n",
    "# Pour afficher les graphiques directement dans le notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 2 : Définir les Fonctions de Prétraitement et d’Augmentation\n",
    "\n",
    "Nous allons définir les fonctions nécessaires pour :\n",
    "\n",
    "- **Augmenter les données audio** (ajout de bruit, modification de la hauteur et de la vitesse).\n",
    "- **Padder ou tronquer les MFCCs** pour assurer une longueur fixe.\n",
    "- **Extraire les MFCCs** avec augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_audio(audio, sr):\n",
    "    \"\"\"\n",
    "    Applique des augmentations sur l'audio : ajout de bruit, modification de la hauteur et de la vitesse.\n",
    "    \"\"\"\n",
    "    # Ajout de bruit\n",
    "    noise = np.random.randn(len(audio)) * 0.005\n",
    "    audio_with_noise = audio + noise\n",
    "\n",
    "    # Modifier la hauteur en fréquence\n",
    "    try:\n",
    "        pitch_factor = np.random.uniform(-5, 5)  # En demi-tons\n",
    "        audio_pitch_shifted = librosa.effects.pitch_shift(audio, sr=sr, n_steps=pitch_factor)\n",
    "    except:\n",
    "        audio_pitch_shifted = audio\n",
    "\n",
    "    # Modifier la vitesse\n",
    "    try:\n",
    "        audio_stretched = librosa.effects.time_stretch(audio, rate=np.random.uniform(0.8, 1.2))\n",
    "    except:\n",
    "        audio_stretched = audio\n",
    "\n",
    "    return [audio_with_noise, audio_pitch_shifted, audio_stretched]\n",
    "\n",
    "def pad_or_truncate_mfcc(mfccs, fixed_length):\n",
    "    \"\"\"\n",
    "    Ajuste la longueur des MFCCs (n_mfcc, T) à (n_mfcc, fixed_length)\n",
    "    - Tronque si T > fixed_length\n",
    "    - Ajoute du padding (zéros) si T < fixed_length\n",
    "    \"\"\"\n",
    "    length = mfccs.shape[1]\n",
    "    if length > fixed_length:\n",
    "        mfccs = mfccs[:, :fixed_length]\n",
    "    elif length < fixed_length:\n",
    "        pad_width = fixed_length - length\n",
    "        mfccs = np.pad(mfccs, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    return mfccs\n",
    "\n",
    "def extract_features_with_augmentation(file_path, fixed_length, n_mfcc=40):\n",
    "    \"\"\"\n",
    "    Extrait les MFCCs d'un fichier audio avec augmentation de données.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, duration=30)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfccs = pad_or_truncate_mfcc(mfccs, fixed_length)\n",
    "\n",
    "        # Augmentations\n",
    "        augmented_audios = augment_audio(audio, sr)\n",
    "        augmented_mfccs = []\n",
    "        for a in augmented_audios:\n",
    "            m = librosa.feature.mfcc(y=a, sr=sr, n_mfcc=n_mfcc)\n",
    "            m = pad_or_truncate_mfcc(m, fixed_length)\n",
    "            augmented_mfccs.append(m)\n",
    "\n",
    "        # On renvoie la liste (original + augmentations) directement sous forme (n_mfcc, T)\n",
    "        all_mfccs = [mfccs] + augmented_mfccs\n",
    "        return all_mfccs\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement du fichier {file_path}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 3 : Définir la Fonction de Création des Modèles\n",
    "\n",
    "Nous allons définir une fonction qui crée différents types de modèles en fonction des hyperparamètres spécifiés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_type, input_shape, num_classes, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Crée un modèle de deep learning en fonction du type spécifié.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    if model_type == 'CNN_2D_basic':\n",
    "        # Modèle CNN 2D de base avec padding 'same'\n",
    "        model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=input_shape))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2,2)))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2,2)))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2,2)))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    elif model_type == 'CNN_2D_deep':\n",
    "        # Modèle CNN 2D plus profond avec padding 'same'\n",
    "        model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=input_shape))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2,2)))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2,2)))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2,2)))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    elif model_type == 'CRNN':\n",
    "        # Modèle Convolutional Recurrent Neural Network avec padding 'same'\n",
    "        model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=input_shape))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2,2)))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2,2)))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(128, return_sequences=True))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(LSTM(64))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    elif model_type == 'CNN_1D':\n",
    "        # Modèle CNN 1D avec padding 'same'\n",
    "        model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=input_shape))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    elif model_type == 'RNN_LSTM':\n",
    "        # Modèle avec couches LSTM\n",
    "        # Reshape pour LSTM : (N, T, n_mfcc)\n",
    "        model.add(Flatten(input_shape=input_shape))  # Convertir en séquence pour LSTM\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(LSTM(128, return_sequences=True))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(LSTM(64))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    elif model_type == 'RNN_GRU':\n",
    "        # Modèle avec couches GRU\n",
    "        # Reshape pour GRU : (N, T, n_mfcc)\n",
    "        model.add(Flatten(input_shape=input_shape))  # Convertir en séquence pour GRU\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(GRU(128, return_sequences=True))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(GRU(64))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Type de modèle inconnu: {model_type}\")\n",
    "\n",
    "    # Compilation du modèle\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 4 : Définir la Fonction de Téléchargement Audio depuis YouTube\n",
    "\n",
    "Cette fonction permet de télécharger un fichier audio depuis une URL YouTube pour tester les prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_audio(youtube_url, output_path=\"downloaded_audio.wav\"):\n",
    "    \"\"\"\n",
    "    Télécharge l'audio d'une vidéo YouTube et le sauvegarde en fichier WAV.\n",
    "    \"\"\"\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': 'temp_audio.%(ext)s',\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'wav',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "    }\n",
    "\n",
    "    # Télécharger l'audio\n",
    "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "\n",
    "    # Renommer le fichier pour l'utiliser\n",
    "    if os.path.exists(\"temp_audio.wav\"):\n",
    "        os.rename(\"temp_audio.wav\", output_path)\n",
    "        print(f\"Audio téléchargé et sauvegardé sous : {output_path}\")\n",
    "    else:\n",
    "        print(\"Erreur lors du téléchargement.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 5 : Initialiser les Hyperparamètres\n",
    "\n",
    "Définissons les différentes valeurs des hyperparamètres que nous allons tester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des hyperparamètres à tester\n",
    "batch_sizes = [16, 32, 64]\n",
    "epochs_list = [20, 50, 100]\n",
    "learning_rates = [0.001, 0.0001, 0.00001]\n",
    "model_types = ['CNN_2D_basic', 'CNN_2D_deep', 'CRNN', 'RNN_LSTM', 'RNN_GRU']  # Ajouter d'autres modèles si nécessaire\n",
    "n_mfcc_values = [20, 40, 60]  # \"token size\" interprété comme nombre de MFCCs\n",
    "\n",
    "# Préparation du tableau de résultats\n",
    "results = []\n",
    "\n",
    "# Créer un répertoire pour sauvegarder les modèles\n",
    "os.makedirs('models', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 6 : Charger et Prétraiter les Données\n",
    "\n",
    "Pour chaque valeur de `n_mfcc`, nous chargerons et prétraiterons les données audio avec augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_features_with_augmentation(data_path, fixed_length, n_mfcc=40):\n",
    "    \"\"\"\n",
    "    Charge les features audio avec augmentation et ajuste les MFCCs à une longueur fixe.\n",
    "    \"\"\"\n",
    "    genres = os.listdir(data_path)\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for genre in genres:\n",
    "        genre_path = os.path.join(data_path, genre)\n",
    "        for file_name in os.listdir(genre_path):\n",
    "            file_path = os.path.join(genre_path, file_name)\n",
    "            mfccs_list = extract_features_with_augmentation(file_path, fixed_length=fixed_length, n_mfcc=n_mfcc)\n",
    "            for m in mfccs_list:\n",
    "                # m est de forme (n_mfcc, fixed_length)\n",
    "                X_list.append(m)\n",
    "                y_list.append(genre)\n",
    "\n",
    "    X = np.array(X_list)  # X: (N, n_mfcc, fixed_length)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    # Ajout de la dimension \"canal\" pour le CNN 2D : (N, n_mfcc, fixed_length, 1)\n",
    "    X = X[..., np.newaxis]\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 7 : Itérer sur les Combinaisons d'Hyperparamètres et Entraîner les Modèles\n",
    "\n",
    "Nous allons maintenant itérer sur toutes les combinaisons possibles d'hyperparamètres et de types de modèles, entraîner chaque modèle, évaluer ses performances, et enregistrer les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_exists(n_mfcc, model_type, batch_size, epochs, lr):\n",
    "    \"\"\"\n",
    "    Vérifie si le modèle avec les hyperparamètres spécifiés existe déjà.\n",
    "    \"\"\"\n",
    "    model_save_path = f\"models/n_mfcc_{n_mfcc}/{model_type}_bs{batch_size}_ep{epochs}_lr{lr}.keras\"\n",
    "    return os.path.exists(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers les données audio\n",
    "data_path = \"Data/genres_original\"\n",
    "\n",
    "# Définir fixed_length en fonction de n_mfcc et des paramètres de vos MFCC\n",
    "fixed_length = 1293  # À ajuster selon votre dataset (en fonction du sr et hop_length)\n",
    "\n",
    "# Itération sur les différentes valeurs de n_mfcc (token size)\n",
    "for n_mfcc in n_mfcc_values:\n",
    "    print(f\"\\nTraitement pour n_mfcc = {n_mfcc}\")\n",
    "    \n",
    "    # Charger les données avec augmentation\n",
    "    X, y = load_audio_features_with_augmentation(data_path, fixed_length, n_mfcc=n_mfcc)\n",
    "\n",
    "    print(f\"Shape des données: X={X.shape}, y={y.shape}\")\n",
    "    \n",
    "    # Encodage des labels\n",
    "    encoder = LabelEncoder()\n",
    "    y_encoded = encoder.fit_transform(y)\n",
    "    y_categorical = to_categorical(y_encoded, num_classes=len(encoder.classes_))\n",
    "\n",
    "    # Sauvegarder l'encodeur (écrasez le précédent si nécessaire)\n",
    "    joblib.dump(encoder, 'label_encoder.joblib')\n",
    "\n",
    "    # Split des données en ensembles d'entraînement et de test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Normalisation des données\n",
    "    # Par exemple, vous pouvez normaliser les MFCCs entre 0 et 1\n",
    "    X_train = X_train / np.max(X_train)\n",
    "    X_test = X_test / np.max(X_test)\n",
    "\n",
    "    # Itération sur les différentes combinaisons d'hyperparamètres\n",
    "    for model_type, batch_size, epochs, lr in itertools.product(model_types, batch_sizes, epochs_list, learning_rates):\n",
    "        print(f\"Entraînement du modèle: {model_type}, Batch Size: {batch_size}, Epochs: {epochs}, Learning Rate: {lr}\")\n",
    "        \n",
    "        # Définir le chemin de sauvegarde du modèle\n",
    "        model_save_path = f\"models/n_mfcc_{n_mfcc}/{model_type}_bs{batch_size}_ep{epochs}_lr{lr}.keras\"\n",
    "        \n",
    "        # Vérifier si le modèle existe déjà\n",
    "        if model_exists(n_mfcc, model_type, batch_size, epochs, lr):\n",
    "            print(f\"Le modèle {model_type} avec bs={batch_size}, ep={epochs}, lr={lr} existe déjà. Passage au suivant.\")\n",
    "            continue  # Passer à la prochaine combinaison\n",
    "        \n",
    "        # Créer le répertoire si nécessaire\n",
    "        os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "        \n",
    "        # Définir le callback EarlyStopping\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        # Définir un ModelCheckpoint pour sauvegarder le meilleur modèle\n",
    "        checkpoint = ModelCheckpoint(model_save_path, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "        \n",
    "        # Définir le modèle\n",
    "        input_shape = X_train.shape[1:]  # (n_mfcc, fixed_length, 1)\n",
    "        num_classes = len(encoder.classes_)\n",
    "        model = create_model(model_type, input_shape, num_classes, learning_rate=lr)\n",
    "\n",
    "        # Entraîner le modèle\n",
    "        history = model.fit(\n",
    "            X_train, y_train, \n",
    "            validation_split=0.2, \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size, \n",
    "            callbacks=[early_stopping, checkpoint], \n",
    "            verbose=1  # Vous pouvez changer en 0 pour moins de sorties\n",
    "        )\n",
    "\n",
    "        # Évaluer le modèle\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        val_loss = min(history.history['val_loss'])\n",
    "        val_accuracy = max(history.history['val_accuracy'])\n",
    "\n",
    "        # Prédictions pour les métriques supplémentaires\n",
    "        y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "        y_true = np.argmax(y_test, axis=-1)\n",
    "        precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        # Enregistrer les résultats\n",
    "        result = {\n",
    "            'n_mfcc': n_mfcc,\n",
    "            'model_type': model_type,\n",
    "            'batch_size': batch_size,\n",
    "            'epochs': epochs,\n",
    "            'learning_rate': lr,\n",
    "            'accuracy': accuracy,\n",
    "            'loss': loss,\n",
    "            'validation_accuracy': val_accuracy,\n",
    "            'validation_loss': val_loss,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "        results.append(result)\n",
    "        print(f\"Résultat: {result}\")\n",
    "\n",
    "        # Sauvegarder les résultats après chaque entraînement pour éviter les pertes en cas d'interruption\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv('model_results.csv', index=False)\n",
    "        print(\"Résultats sauvegardés dans 'model_results.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explications :**\n",
    "\n",
    "- **Itération sur `n_mfcc`** : Pour chaque valeur de `n_mfcc` (nombre de coefficients MFCC), nous chargeons et prétraitons les données.\n",
    "- **Normalisation** : Les MFCCs sont normalisés en divisant par leur maximum pour faciliter la convergence du modèle.\n",
    "- **Boucle Imbriquée** : Utilisation de `itertools.product` pour parcourir toutes les combinaisons possibles des hyperparamètres et des types de modèles.\n",
    "- **Métriques Supplémentaires** : En plus de la précision et de la perte, nous calculons également la précision (`precision_score`), le rappel (`recall_score`) et le score F1 (`f1_score`) pour une évaluation plus complète.\n",
    "- **Sauvegarde des Modèles** : Les meilleurs modèles basés sur la précision de validation sont sauvegardés grâce au `ModelCheckpoint`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 8 : Analyser et Sauvegarder les Résultats\n",
    "\n",
    "Après avoir entraîné tous les modèles, nous allons collecter les résultats dans un tableau et les sauvegarder dans un fichier CSV pour une analyse ultérieure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les résultats en DataFrame et sauvegarder\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('model_results.csv', index=False)\n",
    "print(\"\\nTous les résultats ont été sauvegardés dans 'model_results.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 9 : Visualiser les Meilleurs Résultats\n",
    "\n",
    "Nous allons afficher les 10 meilleures configurations basées sur la précision de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les meilleurs résultats\n",
    "best_results = results_df.sort_values(by='accuracy', ascending=False).head(10)\n",
    "print(\"\\nTop 10 des meilleures configurations :\")\n",
    "display(best_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des Résultats\n",
    "\n",
    "Pour mieux comprendre les performances des différents modèles et hyperparamètres, nous pouvons créer des visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap de la précision en fonction du modèle et du taux d'apprentissage pour chaque n_mfcc\n",
    "for n_mfcc in n_mfcc_values:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    subset = results_df[results_df['n_mfcc'] == n_mfcc]\n",
    "    pivot_table = subset.pivot_table(values='accuracy', index='model_type', columns='learning_rate', aggfunc='mean')\n",
    "    sns.heatmap(pivot_table, annot=True, fmt=\".4f\", cmap='viridis')\n",
    "    plt.title(f\"Précision moyenne par modèle et taux d'apprentissage (n_mfcc={n_mfcc})\")\n",
    "    plt.ylabel(\"Type de Modèle\")\n",
    "    plt.xlabel(\"Taux d'Apprentissage\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot de la précision par type de modèle\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='model_type', y='accuracy', data=results_df)\n",
    "plt.title(\"Distribution de la Précision par Type de Modèle\")\n",
    "plt.xlabel(\"Type de Modèle\")\n",
    "plt.ylabel(\"Précision\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot de la précision en fonction du taux d'apprentissage pour chaque modèle\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.scatterplot(x='learning_rate', y='accuracy', hue='model_type', style='n_mfcc', data=results_df)\n",
    "plt.xscale('log')\n",
    "plt.title(\"Précision en fonction du Taux d'Apprentissage par Type de Modèle\")\n",
    "plt.xlabel(\"Taux d'Apprentissage (échelle logarithmique)\")\n",
    "plt.ylabel(\"Précision\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap de la perte de validation par modèle et taux d'apprentissage pour chaque n_mfcc\n",
    "for n_mfcc in n_mfcc_values:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    subset = results_df[results_df['n_mfcc'] == n_mfcc]\n",
    "    pivot_table = subset.pivot_table(values='validation_loss', index='model_type', columns='learning_rate', aggfunc='mean')\n",
    "    sns.heatmap(pivot_table, annot=True, fmt=\".4f\", cmap='magma')\n",
    "    plt.title(f\"Perte de Validation moyenne par modèle et taux d'apprentissage (n_mfcc={n_mfcc})\")\n",
    "    plt.ylabel(\"Type de Modèle\")\n",
    "    plt.xlabel(\"Taux d'Apprentissage\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explications :**\n",
    "\n",
    "- **Heatmap de la Précision** : Compare la précision moyenne pour chaque type de modèle et taux d'apprentissage, segmenté par `n_mfcc`.\n",
    "- **Boxplot de la Précision** : Montre la distribution de la précision pour chaque type de modèle, permettant d'identifier la variabilité et les performances médianes.\n",
    "- **Scatter Plot de la Précision** : Visualise la relation entre le taux d'apprentissage et la précision, avec une distinction par type de modèle et `n_mfcc`.\n",
    "- **Boxplot du Score F1** : Permet de visualiser la distribution du score F1, une métrique équilibrée entre précision et rappel.\n",
    "- **Heatmap de la Perte de Validation** : Compare la perte de validation moyenne pour chaque type de modèle et taux d'apprentissage, segmenté par `n_mfcc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 10 : Évaluation Approfondie\n",
    "\n",
    "Pour une évaluation plus complète, calculons des métriques supplémentaires telles que le rapport de classification (classification report) et les courbes ROC (si applicable).\n",
    "\n",
    "### 10.1. Rapport de Classification\n",
    "\n",
    "Le rapport de classification fournit la précision, le rappel et le score F1 pour chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner le meilleur modèle basé sur la précision\n",
    "best_result = results_df.sort_values(by='accuracy', ascending=False).iloc[0]\n",
    "best_model_path = f\"models/n_mfcc_{best_result['n_mfcc']}/{best_result['model_type']}_bs{best_result['batch_size']}_ep{best_result['epochs']}_lr{best_result['learning_rate']}.keras\"\n",
    "best_model = load_model(best_model_path)\n",
    "print(f\"\\nChargement du meilleur modèle : {best_model_path}\")\n",
    "\n",
    "# Re-évaluer pour obtenir le rapport de classification\n",
    "y_pred = np.argmax(best_model.predict(X_test), axis=-1)\n",
    "y_true = np.argmax(y_test, axis=-1)\n",
    "\n",
    "print(\"\\nRapport de Classification pour le Meilleur Modèle :\")\n",
    "print(classification_report(y_true, y_pred, target_names=encoder.classes_, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2. Courbes ROC et AUC\n",
    "\n",
    "Pour chaque classe, nous pouvons tracer les courbes ROC et calculer l'AUC. Cependant, cela nécessite des prédictions en probabilités et une binarisation des labels.\n",
    "\n",
    "**Note** : Les courbes ROC sont plus pertinentes pour des problèmes de classification binaire. Pour des classes multiples, nous utilisons une approche \"un contre tous\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Binariser les labels\n",
    "y_true_binarized = label_binarize(y_true, classes=np.arange(len(encoder.classes_)))\n",
    "y_pred_proba = best_model.predict(X_test)\n",
    "\n",
    "# Calculer les courbes ROC et AUC pour chaque classe\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = y_true_binarized.shape[1]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Tracer toutes les courbes ROC\n",
    "plt.figure(figsize=(14, 10))\n",
    "colors = sns.color_palette(\"hls\", n_classes)\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(encoder.classes_[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de Faux Positifs')\n",
    "plt.ylabel('Taux de Vrais Positifs')\n",
    "plt.title('Courbes ROC Multiclasses pour le Meilleur Modèle')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explications :**\n",
    "\n",
    "- **Rapport de Classification** : Fournit une vue détaillée des performances du modèle par classe, y compris la précision, le rappel et le score F1.\n",
    "- **Courbes ROC et AUC** : Mesurent la capacité du modèle à distinguer chaque classe par rapport aux autres. L'AUC (Area Under the Curve) est une mesure globale de performance pour chaque classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3. Matrice de Confusion\n",
    "\n",
    "Bien que vous ayez déjà une matrice de confusion, vous pouvez la refaire pour le meilleur modèle avec une visualisation améliorée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de Confusion pour le Meilleur Modèle\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "ConfusionMatrixDisplay(conf_matrix, display_labels=encoder.classes_).plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Matrice de Confusion pour le Meilleur Modèle\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 11 : Sauvegarder et Charger les Meilleurs Modèles\n",
    "\n",
    "Pour réutiliser les meilleurs modèles sans avoir à les réentraîner, nous pouvons les sauvegarder et les charger ultérieurement.\n",
    "\n",
    "### 11.1. Sauvegarde des Meilleurs Modèles\n",
    "\n",
    "Les modèles sont déjà sauvegardés pendant l'entraînement grâce au callback `ModelCheckpoint`. Assurez-vous que les chemins des modèles sont correctement définis dans les résultats.\n",
    "\n",
    "### 11.2. Chargement d'un Modèle Sauvegardé\n",
    "\n",
    "Voici comment charger un modèle sauvegardé et l'utiliser pour faire des prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de chargement d'un modèle sauvegardé\n",
    "best_result = results_df.sort_values(by='accuracy', ascending=False).iloc[0]\n",
    "best_model_path = f\"models/n_mfcc_{best_result['n_mfcc']}/{best_result['model_type']}_bs{best_result['batch_size']}_ep{best_result['epochs']}_lr{best_result['learning_rate']}.keras\"\n",
    "best_model = load_model(best_model_path)\n",
    "print(f\"\\nChargement du meilleur modèle : {best_model_path}\")\n",
    "\n",
    "# Charger l'encodeur des labels (si non déjà chargé)\n",
    "encoder = joblib.load('label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3. Fonction de Prédiction\n",
    "\n",
    "Voici une fonction de prédiction réutilisable avec le modèle chargé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre(file_path, model, encoder, fixed_length=1293, n_mfcc=40):\n",
    "    \"\"\"\n",
    "    Prédit le genre musical d'un fichier audio.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, duration=30)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfccs = pad_or_truncate_mfcc(mfccs, fixed_length)\n",
    "        mfccs = mfccs[..., np.newaxis]  # Ajouter la dimension canal\n",
    "        mfccs = np.expand_dims(mfccs, axis=0)  # Ajouter la dimension batch\n",
    "\n",
    "        # Normalisation\n",
    "        mfccs = mfccs / np.max(mfccs)\n",
    "\n",
    "        # Prédiction\n",
    "        y_pred_proba = model.predict(mfccs)\n",
    "        predicted_genre_index = np.argmax(y_pred_proba, axis=-1)\n",
    "        predicted_genre = encoder.inverse_transform(predicted_genre_index)[0]\n",
    "        return predicted_genre, y_pred_proba\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la prédiction : {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 12 : Prédiction sur de Nouveaux Échantillons\n",
    "\n",
    "Téléchargeons un nouvel échantillon audio depuis YouTube et effectuons une prédiction en utilisant le meilleur modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger un fichier audio depuis YouTube\n",
    "youtube_url = \"https://youtu.be/tAGnKpE4NCI?si=6me8uc6lZW-LZLrA\" \n",
    "download_youtube_audio(youtube_url, \"test_audio.wav\")\n",
    "\n",
    "# Faire une prédiction\n",
    "predicted_genre, y_pred_proba = predict_genre(\"test_audio.wav\", best_model, encoder, fixed_length=best_result['n_mfcc'], n_mfcc=best_result['n_mfcc'])\n",
    "print(f\"Le genre prédit pour 'test_audio.wav' est : {predicted_genre}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1. Afficher les Probabilités de Prédiction\n",
    "\n",
    "Vous pouvez également afficher les probabilités associées à chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_pred_proba is not None:\n",
    "    probabilities = y_pred_proba.flatten()\n",
    "    genre_probabilities = dict(zip(encoder.classes_, probabilities))\n",
    "    sorted_genres = sorted(genre_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\\nProbabilités de prédiction par genre :\")\n",
    "    for genre, prob in sorted_genres:\n",
    "        print(f\"{genre}: {prob * 100:.2f}%\")\n",
    "\n",
    "    # Bar plot des probabilités\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=list(genre_probabilities.keys()), y=list(genre_probabilities.values()))\n",
    "    plt.title(\"Probabilités de Prédiction par Genre\")\n",
    "    plt.xlabel(\"Genre\")\n",
    "    plt.ylabel(\"Probabilité\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "En suivant ce notebook structuré en blocs, vous pouvez systématiquement tester différentes combinaisons de modèles et d'hyperparamètres pour optimiser la classification des genres musicaux. Voici quelques points clés à retenir :\n",
    "\n",
    "- **Organisation en Blocs** : Chaque étape du processus est clairement séparée, ce qui facilite la maintenance et l'expérimentation.\n",
    "- **Automatisation des Tests** : L'utilisation de boucles imbriquées permet de tester efficacement toutes les combinaisons d'hyperparamètres.\n",
    "- **Métriques Complètes** : En plus de la précision, le rappel et le score F1 fournissent une vue plus équilibrée des performances du modèle, surtout en cas de déséquilibre des classes.\n",
    "- **Visualisation des Résultats** : Les graphiques générés permettent une analyse visuelle rapide des performances des différents modèles et hyperparamètres.\n",
    "- **Sauvegarde des Modèles** : Grâce à `ModelCheckpoint`, les meilleurs modèles sont automatiquement sauvegardés, ce qui évite de perdre les performances optimales obtenues.\n",
    "- **Réutilisation des Modèles** : Les modèles sauvegardés peuvent être facilement chargés pour des prédictions futures sans nécessiter un nouvel entraînement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
